Date,SPARQL endpoint,RDF dump,License Machine-Redeable,License Human-Redeable,KG name,Description,Url,Reliable,Trust value,Degree of connection,Clustring coefficient,Centrality,Number of sameAs chains,Number of triples,KGid,Min latency,25th percentile latency,Median latency,75th percentile latency,Max latency,Min TP,25th percentile TP,Median TP,75th percentile TP,Max TP,Requires auth,Use HTTPS,Serialization formats,Languages,Link SPARQL endpoint,Link for download the dataset,Number of void label,Number of whitespace label,Number of malformed datatype,Labels,Disjoint class,Undefined class,Undefined property,Deprecated class/property,Ontology hijacking,Misplaced property,Misplaced class,PageRank,Vocabularies,Authors,Publishers,Contributors,Sources,Signed,Dataset update frequency,Creation date,Modification date,Num. triples updated,Time since last modification,Extensional conciseness,Intensional conciseness,Interlinking completeness,Number of triples linked,Number of entities,Number of property,Min length URIs (subject),25th percentile length URIs (subject),Median length URIs (subject),75th percentile length URIs (subject),Max length URIs (subject),Min length URIs (predicate),25th percentile length URIs (predicate),Median length URIs (predicate),75th percentile length URIs (predicate),Max length URIs (predicate),Min length URIs (object),25th percentile length URIs (object),Median length URIs (object),75th percentile length URIs (object),Max length URIs (object),New vocabularies defined,New terms defined,Number of label,Uri regex,Presence of example,Number of blank nodes,RDF structures,HistoricalUp,Score,Normalized score,FP,IFP,Limited,defValue,License MR
2022-07-18,-1,0,Creative Commons Attribution - cc-by -,-,zhishi.lemon,[Zhishi.me](http://zhishi.me/) is an effort to build Chinese Linking Open Data. Currently- it covers three largest Chinese encyclopedias: Baidu Baike- Hudong Baike and Chinese Wikipedia. Additional information about Zhishi.me can be found in this [published paper](http://iswc2011.semanticweb.org/fileadmin/iswc/Papers/In-Use/70320209.pdf)[Zhishi.lemon](http://lemon.zhishi.me/) is a newly developed dataset based on the lemon model that constitutes the lexical realization of Zhishi.me. It combines the [lemon core](http://www.lemon-model.net/) with the [lemon translation module](http://linguistic.linkeddata.es/def/translation-content/index.html) in order to build a linked data lexicon in Chinese with translations into Spanish and English. Links to BabelNet (a vast multilingual encyclopedic resource) have been provided as well. The license of the dataset is CC-BY.We also present a [SPARQL endpoint](http://lemon.zhishi.me/sparql.html) for user to query our dataset. For more information- we provide two detailed schema diagrams with several instance examples to help users better understand the dataset and create more valuable SPARQL queries. You can download them from the following two dois: [Chinese Lexicalization Module](https://dx.doi.org/10.6084/m9.figshare.3438545.v1)- [Multilingual Translation Module](https://dx.doi.org/10.6084/m9.figshare.3438548.v1).,Absent,False,0.5,4,0,0.002,-,0,zhishilemon,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,-,-,endpoint absent,endpoint absent,nan,Not provided,-,-,-,endpoint absent,-,-,-,-,endpoint absent,-,-,0.0004291849806313912,endpoint absent,Name: Zhijia Fang; Email:fantorm030@gmail.com,endpoint absent,endpoint absent,Web:Absent Name:East China University of Science and Technology Email:whfcarter@ecust.edu.cn,endpoint absent,endpoint absent,-,-,insufficient data,insufficient data,endpoint absent,endpoint absent,0,542076,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,endpoint absent,False,endpoint absent,endpoint absent,insufficient data,0.325,44.73,-,-,endpoint absent,endpoint absent
